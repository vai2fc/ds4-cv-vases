{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boring-grove",
   "metadata": {},
   "source": [
    "# Model 5: InceptionV3 with Additional, Augmented Training Image Data\n",
    "*Adapted from the [Keras Applications](https://keras.io/api/applications/) page and [Image Classification Tutorial](https://www.tensorflow.org/tutorials/images/classification).*  \n",
    "\n",
    "*This is the fifth pass model for this project. The details:*\n",
    "* Built off of the base of the InceptionV3 architecture with pretrained imagenet weights\n",
    "* Three additional activation layers: a GlobalAveragePooling2D layer, a fully-connected 1,024 neuron relu layer, and a softmax layer to output two classes\n",
    "* Top 2 blocks of the InceptionV3 model unfrozen, thereby permitting training on those layers as well as the layers added to the base model\n",
    "* Trained on 60% of the 5,410 images generated in notebook 02 over the course of 20 epochs, validated against 20% of the data, then tested on a holdout group of 20% of the images\n",
    "* Images in the train and test dataset both normalized to pixel values between 0 and 1 (rather than the original 0 - 255) **and** additional training images created using `ImageDataGenerator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-possession",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries from tensorflow keras (for model building), sklearn (for metrics), matplotlib (for visualization), and np/os/pd (for data processing)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses, activations, models, applications, layers, metrics\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c11c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb09606",
   "metadata": {},
   "source": [
    "### Set up the training / testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a572789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create alternate absolute paths for a pre-split training / testing dataset\n",
    "data_dir_train60 = os.path.dirname(os.getcwd()) + '\\\\data\\\\images-model\\\\train60\\\\'\n",
    "data_dir_val20 = os.path.dirname(os.getcwd()) + '\\\\data\\\\images-model\\\\validate20\\\\'\n",
    "data_dir_test20 = os.path.dirname(os.getcwd()) + '\\\\data\\\\images-model\\\\test20\\\\'\n",
    "\n",
    "# show the paths created\n",
    "# print(data_dir)\n",
    "# print(data_dir_train)\n",
    "# print(data_dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a4609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for the model here\n",
    "# number of images per batch\n",
    "batch_size = 32\n",
    "\n",
    "# all images have been resized to 558x558 pixels, the median size of a kithara in the dataset\n",
    "img_height = 558\n",
    "img_width = 558"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e8ae7",
   "metadata": {},
   "source": [
    "#### Use the 60/20/20 train/validation/test split from notebook 02 and augment the training dataset\n",
    "*Note that `shuffle = True` [by default](https://stackoverflow.com/questions/62166588/how-to-obtain-filenames-during-prediction-while-using-tf-keras-preprocessing-ima). Explicitly set `shuffle = False` for the test dataset in order to ensure alignment across the labels and file names (see [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)).*  \n",
    "\n",
    "*In addition, note that the training data generator rescales and randomly generates rotated, shifted up and down, brighter and darker, sheared, zoomed, and horizontally-flipped images, whereas the test generator only rescales the images fed to it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5ec7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 05a\n",
    "# # create an image data generator for the training and testing images\n",
    "# train_datagen = image.ImageDataGenerator(\n",
    "#         rescale=1./255,\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True)\n",
    "\n",
    "# test_datagen = image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fa135b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05b\n",
    "# create an image data generator for the training and testing images\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "                rescale = 1./255,\n",
    "                rotation_range = 90,\n",
    "                width_shift_range = 0.2,\n",
    "                height_shift_range = 0.2,\n",
    "                brightness_range = [0.5, 1.5],\n",
    "                shear_range = 0.2,\n",
    "                zoom_range = 0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "test_datagen = image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9674524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3246 images belonging to 2 classes.\n",
      "Found 1082 images belonging to 2 classes.\n",
      "Found 1082 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a training and testing dataset from the pre-processed images\n",
    "# this code uses the train/test split already specified in notebook 02\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    data_dir_train60,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = True,\n",
    "    seed = 42)\n",
    "\n",
    "# create a validation dataset from the pre-processed images\n",
    "val_gen = test_datagen.flow_from_directory(\n",
    "    data_dir_val20,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    "    seed = 42)\n",
    "\n",
    "# create a testing dataset from the pre-processed images\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    data_dir_test20,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    shuffle = False,\n",
    "    seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa806ad9",
   "metadata": {},
   "source": [
    "#### Get some identifying information about the files in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac33d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the location of the files in the test dataset\n",
    "filepaths = test_gen.filenames\n",
    "# get the labels of the files in the test dataset\n",
    "test_labels = test_gen.classes\n",
    "# confirm the order of the classes\n",
    "class_names = test_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ffd76d",
   "metadata": {},
   "source": [
    "### Build a base model from the InceptionV3 model architecture\n",
    "\n",
    "*N.B. this is the same base model as in notebook 03a. The main exception is that the top two blocks of InceptionV3 are also trainable now.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fourth-helping",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate the base model, using pretrained weights from imagenet\n",
    "# note that if this does not run, downgrade h5py\n",
    "# pip install \"h5py==2.10.0\" --force-reinstall\n",
    "base_model = applications.InceptionV3(weights = 'imagenet',\n",
    "                                      include_top=False,\n",
    "                                      input_shape = (img_height, img_width, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b4f6e",
   "metadata": {},
   "source": [
    "#### Add customizations to the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inclusive-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and add a logistic layer -- output should be the number of classes (in this case, 2)\n",
    "predictions = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threatened-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "english-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv2d\n",
      "2 batch_normalization\n",
      "3 activation\n",
      "4 conv2d_1\n",
      "5 batch_normalization_1\n",
      "6 activation_1\n",
      "7 conv2d_2\n",
      "8 batch_normalization_2\n",
      "9 activation_2\n",
      "10 max_pooling2d\n",
      "11 conv2d_3\n",
      "12 batch_normalization_3\n",
      "13 activation_3\n",
      "14 conv2d_4\n",
      "15 batch_normalization_4\n",
      "16 activation_4\n",
      "17 max_pooling2d_1\n",
      "18 conv2d_8\n",
      "19 batch_normalization_8\n",
      "20 activation_8\n",
      "21 conv2d_6\n",
      "22 conv2d_9\n",
      "23 batch_normalization_6\n",
      "24 batch_normalization_9\n",
      "25 activation_6\n",
      "26 activation_9\n",
      "27 average_pooling2d\n",
      "28 conv2d_5\n",
      "29 conv2d_7\n",
      "30 conv2d_10\n",
      "31 conv2d_11\n",
      "32 batch_normalization_5\n",
      "33 batch_normalization_7\n",
      "34 batch_normalization_10\n",
      "35 batch_normalization_11\n",
      "36 activation_5\n",
      "37 activation_7\n",
      "38 activation_10\n",
      "39 activation_11\n",
      "40 mixed0\n",
      "41 conv2d_15\n",
      "42 batch_normalization_15\n",
      "43 activation_15\n",
      "44 conv2d_13\n",
      "45 conv2d_16\n",
      "46 batch_normalization_13\n",
      "47 batch_normalization_16\n",
      "48 activation_13\n",
      "49 activation_16\n",
      "50 average_pooling2d_1\n",
      "51 conv2d_12\n",
      "52 conv2d_14\n",
      "53 conv2d_17\n",
      "54 conv2d_18\n",
      "55 batch_normalization_12\n",
      "56 batch_normalization_14\n",
      "57 batch_normalization_17\n",
      "58 batch_normalization_18\n",
      "59 activation_12\n",
      "60 activation_14\n",
      "61 activation_17\n",
      "62 activation_18\n",
      "63 mixed1\n",
      "64 conv2d_22\n",
      "65 batch_normalization_22\n",
      "66 activation_22\n",
      "67 conv2d_20\n",
      "68 conv2d_23\n",
      "69 batch_normalization_20\n",
      "70 batch_normalization_23\n",
      "71 activation_20\n",
      "72 activation_23\n",
      "73 average_pooling2d_2\n",
      "74 conv2d_19\n",
      "75 conv2d_21\n",
      "76 conv2d_24\n",
      "77 conv2d_25\n",
      "78 batch_normalization_19\n",
      "79 batch_normalization_21\n",
      "80 batch_normalization_24\n",
      "81 batch_normalization_25\n",
      "82 activation_19\n",
      "83 activation_21\n",
      "84 activation_24\n",
      "85 activation_25\n",
      "86 mixed2\n",
      "87 conv2d_27\n",
      "88 batch_normalization_27\n",
      "89 activation_27\n",
      "90 conv2d_28\n",
      "91 batch_normalization_28\n",
      "92 activation_28\n",
      "93 conv2d_26\n",
      "94 conv2d_29\n",
      "95 batch_normalization_26\n",
      "96 batch_normalization_29\n",
      "97 activation_26\n",
      "98 activation_29\n",
      "99 max_pooling2d_2\n",
      "100 mixed3\n",
      "101 conv2d_34\n",
      "102 batch_normalization_34\n",
      "103 activation_34\n",
      "104 conv2d_35\n",
      "105 batch_normalization_35\n",
      "106 activation_35\n",
      "107 conv2d_31\n",
      "108 conv2d_36\n",
      "109 batch_normalization_31\n",
      "110 batch_normalization_36\n",
      "111 activation_31\n",
      "112 activation_36\n",
      "113 conv2d_32\n",
      "114 conv2d_37\n",
      "115 batch_normalization_32\n",
      "116 batch_normalization_37\n",
      "117 activation_32\n",
      "118 activation_37\n",
      "119 average_pooling2d_3\n",
      "120 conv2d_30\n",
      "121 conv2d_33\n",
      "122 conv2d_38\n",
      "123 conv2d_39\n",
      "124 batch_normalization_30\n",
      "125 batch_normalization_33\n",
      "126 batch_normalization_38\n",
      "127 batch_normalization_39\n",
      "128 activation_30\n",
      "129 activation_33\n",
      "130 activation_38\n",
      "131 activation_39\n",
      "132 mixed4\n",
      "133 conv2d_44\n",
      "134 batch_normalization_44\n",
      "135 activation_44\n",
      "136 conv2d_45\n",
      "137 batch_normalization_45\n",
      "138 activation_45\n",
      "139 conv2d_41\n",
      "140 conv2d_46\n",
      "141 batch_normalization_41\n",
      "142 batch_normalization_46\n",
      "143 activation_41\n",
      "144 activation_46\n",
      "145 conv2d_42\n",
      "146 conv2d_47\n",
      "147 batch_normalization_42\n",
      "148 batch_normalization_47\n",
      "149 activation_42\n",
      "150 activation_47\n",
      "151 average_pooling2d_4\n",
      "152 conv2d_40\n",
      "153 conv2d_43\n",
      "154 conv2d_48\n",
      "155 conv2d_49\n",
      "156 batch_normalization_40\n",
      "157 batch_normalization_43\n",
      "158 batch_normalization_48\n",
      "159 batch_normalization_49\n",
      "160 activation_40\n",
      "161 activation_43\n",
      "162 activation_48\n",
      "163 activation_49\n",
      "164 mixed5\n",
      "165 conv2d_54\n",
      "166 batch_normalization_54\n",
      "167 activation_54\n",
      "168 conv2d_55\n",
      "169 batch_normalization_55\n",
      "170 activation_55\n",
      "171 conv2d_51\n",
      "172 conv2d_56\n",
      "173 batch_normalization_51\n",
      "174 batch_normalization_56\n",
      "175 activation_51\n",
      "176 activation_56\n",
      "177 conv2d_52\n",
      "178 conv2d_57\n",
      "179 batch_normalization_52\n",
      "180 batch_normalization_57\n",
      "181 activation_52\n",
      "182 activation_57\n",
      "183 average_pooling2d_5\n",
      "184 conv2d_50\n",
      "185 conv2d_53\n",
      "186 conv2d_58\n",
      "187 conv2d_59\n",
      "188 batch_normalization_50\n",
      "189 batch_normalization_53\n",
      "190 batch_normalization_58\n",
      "191 batch_normalization_59\n",
      "192 activation_50\n",
      "193 activation_53\n",
      "194 activation_58\n",
      "195 activation_59\n",
      "196 mixed6\n",
      "197 conv2d_64\n",
      "198 batch_normalization_64\n",
      "199 activation_64\n",
      "200 conv2d_65\n",
      "201 batch_normalization_65\n",
      "202 activation_65\n",
      "203 conv2d_61\n",
      "204 conv2d_66\n",
      "205 batch_normalization_61\n",
      "206 batch_normalization_66\n",
      "207 activation_61\n",
      "208 activation_66\n",
      "209 conv2d_62\n",
      "210 conv2d_67\n",
      "211 batch_normalization_62\n",
      "212 batch_normalization_67\n",
      "213 activation_62\n",
      "214 activation_67\n",
      "215 average_pooling2d_6\n",
      "216 conv2d_60\n",
      "217 conv2d_63\n",
      "218 conv2d_68\n",
      "219 conv2d_69\n",
      "220 batch_normalization_60\n",
      "221 batch_normalization_63\n",
      "222 batch_normalization_68\n",
      "223 batch_normalization_69\n",
      "224 activation_60\n",
      "225 activation_63\n",
      "226 activation_68\n",
      "227 activation_69\n",
      "228 mixed7\n",
      "229 conv2d_72\n",
      "230 batch_normalization_72\n",
      "231 activation_72\n",
      "232 conv2d_73\n",
      "233 batch_normalization_73\n",
      "234 activation_73\n",
      "235 conv2d_70\n",
      "236 conv2d_74\n",
      "237 batch_normalization_70\n",
      "238 batch_normalization_74\n",
      "239 activation_70\n",
      "240 activation_74\n",
      "241 conv2d_71\n",
      "242 conv2d_75\n",
      "243 batch_normalization_71\n",
      "244 batch_normalization_75\n",
      "245 activation_71\n",
      "246 activation_75\n",
      "247 max_pooling2d_3\n",
      "248 mixed8\n",
      "249 conv2d_80\n",
      "250 batch_normalization_80\n",
      "251 activation_80\n",
      "252 conv2d_77\n",
      "253 conv2d_81\n",
      "254 batch_normalization_77\n",
      "255 batch_normalization_81\n",
      "256 activation_77\n",
      "257 activation_81\n",
      "258 conv2d_78\n",
      "259 conv2d_79\n",
      "260 conv2d_82\n",
      "261 conv2d_83\n",
      "262 average_pooling2d_7\n",
      "263 conv2d_76\n",
      "264 batch_normalization_78\n",
      "265 batch_normalization_79\n",
      "266 batch_normalization_82\n",
      "267 batch_normalization_83\n",
      "268 conv2d_84\n",
      "269 batch_normalization_76\n",
      "270 activation_78\n",
      "271 activation_79\n",
      "272 activation_82\n",
      "273 activation_83\n",
      "274 batch_normalization_84\n",
      "275 activation_76\n",
      "276 mixed9_0\n",
      "277 concatenate\n",
      "278 activation_84\n",
      "279 mixed9\n",
      "280 conv2d_89\n",
      "281 batch_normalization_89\n",
      "282 activation_89\n",
      "283 conv2d_86\n",
      "284 conv2d_90\n",
      "285 batch_normalization_86\n",
      "286 batch_normalization_90\n",
      "287 activation_86\n",
      "288 activation_90\n",
      "289 conv2d_87\n",
      "290 conv2d_88\n",
      "291 conv2d_91\n",
      "292 conv2d_92\n",
      "293 average_pooling2d_8\n",
      "294 conv2d_85\n",
      "295 batch_normalization_87\n",
      "296 batch_normalization_88\n",
      "297 batch_normalization_91\n",
      "298 batch_normalization_92\n",
      "299 conv2d_93\n",
      "300 batch_normalization_85\n",
      "301 activation_87\n",
      "302 activation_88\n",
      "303 activation_91\n",
      "304 activation_92\n",
      "305 batch_normalization_93\n",
      "306 activation_85\n",
      "307 mixed9_1\n",
      "308 concatenate_1\n",
      "309 activation_93\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "# look at the inceptionv3 layer names and layer indices to see how many layers the base model has\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tamil-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the top 2 inception blocks\n",
    "# i.e. freeze the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fbc9b",
   "metadata": {},
   "source": [
    "#### Compile and review the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cloudy-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['BinaryAccuracy',\n",
    "                        'FalseNegatives',\n",
    "                        'FalsePositives',\n",
    "                        'TrueNegatives',\n",
    "                        'TruePositives',\n",
    "                        'AUC',\n",
    "                        'Precision',\n",
    "                        'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9a5b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 558, 558, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 278, 278, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 278, 278, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 278, 278, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 276, 276, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 276, 276, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 276, 276, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 276, 276, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 276, 276, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 276, 276, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 137, 137, 64) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 137, 137, 80) 5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 137, 137, 80) 240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 137, 137, 80) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 135, 135, 192 138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 135, 135, 192 576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 135, 135, 192 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 67, 67, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 67, 67, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 67, 67, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 67, 67, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 67, 67, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 67, 67, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 67, 67, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 67, 67, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 67, 67, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 67, 67, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 67, 67, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 67, 67, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 67, 67, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 67, 67, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 67, 67, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 67, 67, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 67, 67, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 67, 67, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 67, 67, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 67, 67, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 67, 67, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 67, 67, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 67, 67, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 67, 67, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 67, 67, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 67, 67, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 67, 67, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 67, 67, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 67, 67, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 67, 67, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 67, 67, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 67, 67, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 67, 67, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 67, 67, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 67, 67, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 67, 67, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 67, 67, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 67, 67, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 67, 67, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 67, 67, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 67, 67, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 67, 67, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 67, 67, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 67, 67, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 67, 67, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 67, 67, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 67, 67, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 67, 67, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 67, 67, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 67, 67, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 67, 67, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 67, 67, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 67, 67, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 67, 67, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 67, 67, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 67, 67, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 67, 67, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 67, 67, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 67, 67, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 67, 67, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 67, 67, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 67, 67, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 67, 67, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 67, 67, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 67, 67, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 67, 67, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 67, 67, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 67, 67, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 67, 67, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 67, 67, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 67, 67, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 67, 67, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 67, 67, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 67, 67, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 67, 67, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 67, 67, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 33, 33, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 33, 33, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 33, 33, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 33, 33, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 33, 33, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 33, 33, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 33, 33, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 33, 33, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 33, 33, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 33, 33, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 33, 33, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 33, 33, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 33, 33, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 33, 33, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 33, 33, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 33, 33, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 33, 33, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 33, 33, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 33, 33, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 33, 33, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 33, 33, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 33, 33, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 33, 33, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 33, 33, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 33, 33, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 33, 33, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 33, 33, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 33, 33, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 33, 33, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 33, 33, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 33, 33, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 33, 33, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 33, 33, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 33, 33, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 33, 33, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 33, 33, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 33, 33, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 33, 33, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 33, 33, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 33, 33, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 33, 33, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 33, 33, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 33, 33, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 33, 33, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 33, 33, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 33, 33, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 33, 33, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 33, 33, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 33, 33, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 33, 33, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 33, 33, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 33, 33, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 33, 33, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 33, 33, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 33, 33, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 33, 33, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 33, 33, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 33, 33, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 33, 33, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 33, 33, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 33, 33, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 33, 33, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 33, 33, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 33, 33, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 33, 33, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 33, 33, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 33, 33, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 33, 33, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 33, 33, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 33, 33, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 33, 33, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 33, 33, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 33, 33, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 33, 33, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 33, 33, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 33, 33, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 33, 33, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 33, 33, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 33, 33, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 33, 33, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 33, 33, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 33, 33, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 33, 33, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 33, 33, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 33, 33, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 33, 33, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 33, 33, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 33, 33, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 33, 33, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 33, 33, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 33, 33, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 33, 33, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 33, 33, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 33, 33, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 33, 33, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 33, 33, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 33, 33, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 33, 33, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 33, 33, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 33, 33, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 33, 33, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 33, 33, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 33, 33, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 33, 33, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 33, 33, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 33, 33, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 33, 33, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 33, 33, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 33, 33, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 33, 33, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 33, 33, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 33, 33, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 33, 33, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 33, 33, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 33, 33, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 33, 33, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 33, 33, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 33, 33, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 33, 33, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 33, 33, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 33, 33, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 33, 33, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 33, 33, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 33, 33, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 33, 33, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 33, 33, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 33, 33, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 33, 33, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 33, 33, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 33, 33, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 33, 33, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 33, 33, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 33, 33, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 33, 33, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 33, 33, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 33, 33, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 33, 33, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 33, 33, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 33, 33, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 33, 33, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 33, 33, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 33, 33, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 33, 33, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 33, 33, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 33, 33, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 33, 33, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 33, 33, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 33, 33, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 320)  552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 192)  331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 320)  960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 320)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 768)  0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 16, 16, 1280) 0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 448)  573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 448)  1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 16, 448)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 384)  491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 384)  1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 384)  1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 384)  1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 384)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 384)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 384)  442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 16, 16, 384)  442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 384)  442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 384)  442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 16, 16, 1280) 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 320)  409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 16, 16, 384)  1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 384)  1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 384)  1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 384)  1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 192)  245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 320)  960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 16, 16, 384)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 384)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 384)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 16, 16, 384)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 192)  576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 320)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 16, 16, 768)  0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 768)  0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 192)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 16, 16, 2048) 0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 448)  917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 448)  1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 448)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 384)  786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 384)  1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 384)  1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 16, 16, 384)  1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 384)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 16, 16, 384)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 384)  442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 384)  442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 384)  442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 16, 16, 384)  442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 16, 16, 2048) 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 320)  655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 384)  1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 384)  1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 16, 16, 384)  1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 16, 16, 384)  1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 16, 16, 192)  393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 320)  960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 384)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 384)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 16, 16, 384)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 16, 16, 384)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 16, 16, 192)  576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 320)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 16, 16, 768)  0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 16, 16, 768)  0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 16, 16, 192)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 16, 16, 2048) 0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# take a look at the model layer-by-layer\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c538c",
   "metadata": {},
   "source": [
    "#### Create checkpoints for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4005e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model_checkpoints/training_05/cp-{epoch}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# create a callback that saves the model's weights after each training run\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq = 'epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2208d15",
   "metadata": {},
   "source": [
    "### Fit model on the training data with transformations and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f24cbc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 698s 7s/step - loss: 0.1576 - binary_accuracy: 0.9449 - false_negatives: 179.0000 - false_positives: 179.0000 - true_negatives: 3067.0000 - true_positives: 3067.0000 - auc: 0.9827 - precision: 0.9449 - recall: 0.9449 - val_loss: 0.3429 - val_binary_accuracy: 0.9630 - val_false_negatives: 40.0000 - val_false_positives: 40.0000 - val_true_negatives: 1042.0000 - val_true_positives: 1042.0000 - val_auc: 0.9706 - val_precision: 0.9630 - val_recall: 0.9630\n",
      "\n",
      "Epoch 00001: saving model to model_checkpoints/training_05\\cp-1.ckpt\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 690s 7s/step - loss: 0.0979 - binary_accuracy: 0.9661 - false_negatives: 110.0000 - false_positives: 110.0000 - true_negatives: 3136.0000 - true_positives: 3136.0000 - auc: 0.9888 - precision: 0.9661 - recall: 0.9661 - val_loss: 0.1536 - val_binary_accuracy: 0.9741 - val_false_negatives: 28.0000 - val_false_positives: 28.0000 - val_true_negatives: 1054.0000 - val_true_positives: 1054.0000 - val_auc: 0.9809 - val_precision: 0.9741 - val_recall: 0.9741\n",
      "\n",
      "Epoch 00002: saving model to model_checkpoints/training_05\\cp-2.ckpt\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 681s 7s/step - loss: 0.0845 - binary_accuracy: 0.9670 - false_negatives: 107.0000 - false_positives: 107.0000 - true_negatives: 3139.0000 - true_positives: 3139.0000 - auc: 0.9927 - precision: 0.9670 - recall: 0.9670 - val_loss: 0.5485 - val_binary_accuracy: 0.9529 - val_false_negatives: 51.0000 - val_false_positives: 51.0000 - val_true_negatives: 1031.0000 - val_true_positives: 1031.0000 - val_auc: 0.9647 - val_precision: 0.9529 - val_recall: 0.9529\n",
      "\n",
      "Epoch 00003: saving model to model_checkpoints/training_05\\cp-3.ckpt\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 682s 7s/step - loss: 0.0750 - binary_accuracy: 0.9750 - false_negatives: 81.0000 - false_positives: 81.0000 - true_negatives: 3165.0000 - true_positives: 3165.0000 - auc: 0.9910 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.0784 - val_binary_accuracy: 0.9797 - val_false_negatives: 22.0000 - val_false_positives: 22.0000 - val_true_negatives: 1060.0000 - val_true_positives: 1060.0000 - val_auc: 0.9908 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "\n",
      "Epoch 00004: saving model to model_checkpoints/training_05\\cp-4.ckpt\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 678s 7s/step - loss: 0.0676 - binary_accuracy: 0.9760 - false_negatives: 78.0000 - false_positives: 78.0000 - true_negatives: 3168.0000 - true_positives: 3168.0000 - auc: 0.9944 - precision: 0.9760 - recall: 0.9760 - val_loss: 0.0623 - val_binary_accuracy: 0.9797 - val_false_negatives: 22.0000 - val_false_positives: 22.0000 - val_true_negatives: 1060.0000 - val_true_positives: 1060.0000 - val_auc: 0.9929 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "\n",
      "Epoch 00005: saving model to model_checkpoints/training_05\\cp-5.ckpt\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 678s 7s/step - loss: 0.0582 - binary_accuracy: 0.9784 - false_negatives: 70.0000 - false_positives: 70.0000 - true_negatives: 3176.0000 - true_positives: 3176.0000 - auc: 0.9944 - precision: 0.9784 - recall: 0.9784 - val_loss: 0.1541 - val_binary_accuracy: 0.9750 - val_false_negatives: 27.0000 - val_false_positives: 27.0000 - val_true_negatives: 1055.0000 - val_true_positives: 1055.0000 - val_auc: 0.9856 - val_precision: 0.9750 - val_recall: 0.9750\n",
      "\n",
      "Epoch 00006: saving model to model_checkpoints/training_05\\cp-6.ckpt\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 677s 7s/step - loss: 0.0585 - binary_accuracy: 0.9827 - false_negatives: 56.0000 - false_positives: 56.0000 - true_negatives: 3190.0000 - true_positives: 3190.0000 - auc: 0.9926 - precision: 0.9827 - recall: 0.9827 - val_loss: 0.0618 - val_binary_accuracy: 0.9797 - val_false_negatives: 22.0000 - val_false_positives: 22.0000 - val_true_negatives: 1060.0000 - val_true_positives: 1060.0000 - val_auc: 0.9918 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "\n",
      "Epoch 00007: saving model to model_checkpoints/training_05\\cp-7.ckpt\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 681s 7s/step - loss: 0.0514 - binary_accuracy: 0.9827 - false_negatives: 56.0000 - false_positives: 56.0000 - true_negatives: 3190.0000 - true_positives: 3190.0000 - auc: 0.9949 - precision: 0.9827 - recall: 0.9827 - val_loss: 0.0612 - val_binary_accuracy: 0.9815 - val_false_negatives: 20.0000 - val_false_positives: 20.0000 - val_true_negatives: 1062.0000 - val_true_positives: 1062.0000 - val_auc: 0.9930 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "\n",
      "Epoch 00008: saving model to model_checkpoints/training_05\\cp-8.ckpt\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 698s 7s/step - loss: 0.0444 - binary_accuracy: 0.9855 - false_negatives: 47.0000 - false_positives: 47.0000 - true_negatives: 3199.0000 - true_positives: 3199.0000 - auc: 0.9951 - precision: 0.9855 - recall: 0.9855 - val_loss: 0.0694 - val_binary_accuracy: 0.9806 - val_false_negatives: 21.0000 - val_false_positives: 21.0000 - val_true_negatives: 1061.0000 - val_true_positives: 1061.0000 - val_auc: 0.9921 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00009: saving model to model_checkpoints/training_05\\cp-9.ckpt\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 702s 7s/step - loss: 0.0549 - binary_accuracy: 0.9827 - false_negatives: 56.0000 - false_positives: 56.0000 - true_negatives: 3190.0000 - true_positives: 3190.0000 - auc: 0.9954 - precision: 0.9827 - recall: 0.9827 - val_loss: 0.0748 - val_binary_accuracy: 0.9787 - val_false_negatives: 23.0000 - val_false_positives: 23.0000 - val_true_negatives: 1059.0000 - val_true_positives: 1059.0000 - val_auc: 0.9883 - val_precision: 0.9787 - val_recall: 0.9787\n",
      "\n",
      "Epoch 00010: saving model to model_checkpoints/training_05\\cp-10.ckpt\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 707s 7s/step - loss: 0.0483 - binary_accuracy: 0.9837 - false_negatives: 53.0000 - false_positives: 53.0000 - true_negatives: 3193.0000 - true_positives: 3193.0000 - auc: 0.9949 - precision: 0.9837 - recall: 0.9837 - val_loss: 0.0675 - val_binary_accuracy: 0.9843 - val_false_negatives: 17.0000 - val_false_positives: 17.0000 - val_true_negatives: 1065.0000 - val_true_positives: 1065.0000 - val_auc: 0.9923 - val_precision: 0.9843 - val_recall: 0.9843\n",
      "\n",
      "Epoch 00011: saving model to model_checkpoints/training_05\\cp-11.ckpt\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 699s 7s/step - loss: 0.0569 - binary_accuracy: 0.9824 - false_negatives: 57.0000 - false_positives: 57.0000 - true_negatives: 3189.0000 - true_positives: 3189.0000 - auc: 0.9941 - precision: 0.9824 - recall: 0.9824 - val_loss: 0.0732 - val_binary_accuracy: 0.9787 - val_false_negatives: 23.0000 - val_false_positives: 23.0000 - val_true_negatives: 1059.0000 - val_true_positives: 1059.0000 - val_auc: 0.9901 - val_precision: 0.9787 - val_recall: 0.9787\n",
      "\n",
      "Epoch 00012: saving model to model_checkpoints/training_05\\cp-12.ckpt\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 704s 7s/step - loss: 0.0430 - binary_accuracy: 0.9880 - false_negatives: 39.0000 - false_positives: 39.0000 - true_negatives: 3207.0000 - true_positives: 3207.0000 - auc: 0.9962 - precision: 0.9880 - recall: 0.9880 - val_loss: 0.0670 - val_binary_accuracy: 0.9815 - val_false_negatives: 20.0000 - val_false_positives: 20.0000 - val_true_negatives: 1062.0000 - val_true_positives: 1062.0000 - val_auc: 0.9902 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "\n",
      "Epoch 00013: saving model to model_checkpoints/training_05\\cp-13.ckpt\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 707s 7s/step - loss: 0.0461 - binary_accuracy: 0.9831 - false_negatives: 55.0000 - false_positives: 55.0000 - true_negatives: 3191.0000 - true_positives: 3191.0000 - auc: 0.9963 - precision: 0.9831 - recall: 0.9831 - val_loss: 0.0513 - val_binary_accuracy: 0.9797 - val_false_negatives: 22.0000 - val_false_positives: 22.0000 - val_true_negatives: 1060.0000 - val_true_positives: 1060.0000 - val_auc: 0.9947 - val_precision: 0.9797 - val_recall: 0.9797\n",
      "\n",
      "Epoch 00014: saving model to model_checkpoints/training_05\\cp-14.ckpt\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 709s 7s/step - loss: 0.0485 - binary_accuracy: 0.9840 - false_negatives: 52.0000 - false_positives: 52.0000 - true_negatives: 3194.0000 - true_positives: 3194.0000 - auc: 0.9947 - precision: 0.9840 - recall: 0.9840 - val_loss: 0.0998 - val_binary_accuracy: 0.9750 - val_false_negatives: 27.0000 - val_false_positives: 27.0000 - val_true_negatives: 1055.0000 - val_true_positives: 1055.0000 - val_auc: 0.9862 - val_precision: 0.9750 - val_recall: 0.9750\n",
      "\n",
      "Epoch 00015: saving model to model_checkpoints/training_05\\cp-15.ckpt\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 704s 7s/step - loss: 0.0415 - binary_accuracy: 0.9883 - false_negatives: 38.0000 - false_positives: 38.0000 - true_negatives: 3208.0000 - true_positives: 3208.0000 - auc: 0.9959 - precision: 0.9883 - recall: 0.9883 - val_loss: 0.0597 - val_binary_accuracy: 0.9806 - val_false_negatives: 21.0000 - val_false_positives: 21.0000 - val_true_negatives: 1061.0000 - val_true_positives: 1061.0000 - val_auc: 0.9921 - val_precision: 0.9806 - val_recall: 0.9806\n",
      "\n",
      "Epoch 00016: saving model to model_checkpoints/training_05\\cp-16.ckpt\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 700s 7s/step - loss: 0.0315 - binary_accuracy: 0.9871 - false_negatives: 42.0000 - false_positives: 42.0000 - true_negatives: 3204.0000 - true_positives: 3204.0000 - auc: 0.9972 - precision: 0.9871 - recall: 0.9871 - val_loss: 0.0836 - val_binary_accuracy: 0.9824 - val_false_negatives: 19.0000 - val_false_positives: 19.0000 - val_true_negatives: 1063.0000 - val_true_positives: 1063.0000 - val_auc: 0.9868 - val_precision: 0.9824 - val_recall: 0.9824\n",
      "\n",
      "Epoch 00017: saving model to model_checkpoints/training_05\\cp-17.ckpt\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 700s 7s/step - loss: 0.0329 - binary_accuracy: 0.9901 - false_negatives: 32.0000 - false_positives: 32.0000 - true_negatives: 3214.0000 - true_positives: 3214.0000 - auc: 0.9957 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0416 - val_binary_accuracy: 0.9861 - val_false_negatives: 15.0000 - val_false_positives: 15.0000 - val_true_negatives: 1067.0000 - val_true_positives: 1067.0000 - val_auc: 0.9951 - val_precision: 0.9861 - val_recall: 0.9861\n",
      "\n",
      "Epoch 00018: saving model to model_checkpoints/training_05\\cp-18.ckpt\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 705s 7s/step - loss: 0.0371 - binary_accuracy: 0.9889 - false_negatives: 36.0000 - false_positives: 36.0000 - true_negatives: 3210.0000 - true_positives: 3210.0000 - auc: 0.9965 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.0649 - val_binary_accuracy: 0.9834 - val_false_negatives: 18.0000 - val_false_positives: 18.0000 - val_true_negatives: 1064.0000 - val_true_positives: 1064.0000 - val_auc: 0.9905 - val_precision: 0.9834 - val_recall: 0.9834\n",
      "\n",
      "Epoch 00019: saving model to model_checkpoints/training_05\\cp-19.ckpt\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 705s 7s/step - loss: 0.0314 - binary_accuracy: 0.9904 - false_negatives: 31.0000 - false_positives: 31.0000 - true_negatives: 3215.0000 - true_positives: 3215.0000 - auc: 0.9963 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.0641 - val_binary_accuracy: 0.9815 - val_false_negatives: 20.0000 - val_false_positives: 20.0000 - val_true_negatives: 1062.0000 - val_true_positives: 1062.0000 - val_auc: 0.9913 - val_precision: 0.9815 - val_recall: 0.9815\n",
      "\n",
      "Epoch 00020: saving model to model_checkpoints/training_05\\cp-20.ckpt\n"
     ]
    }
   ],
   "source": [
    "# set the number of passes over the entire dataset as the number of epochs\n",
    "epochs = 20\n",
    "\n",
    "# fit the model based on the normalized training data\n",
    "# write the comparative metrics on the normalized training and testing data to history\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data = val_gen,\n",
    "    epochs=epochs,\n",
    "    callbacks = [cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff6ec4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model-05\\assets\n"
     ]
    }
   ],
   "source": [
    "# save the model to utilize later\n",
    "model.save('saved_models/model-05')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc84287",
   "metadata": {},
   "source": [
    "### Predict the probability that an image contains a chordophone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8efd2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability of kithara / no-kithara label of the normalized_val_ds images\n",
    "# N.B. COMMENT OUT THIS CELL ONCE IT HAS BEEN RUN TO PREVENT ACCIDENTALLY RE-RUNNING IT\n",
    "test_predictions = model.predict(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1de70b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[1. 1.]\n",
      "{'kithara': 0, 'no-kithara': 1}\n",
      "[[9.2459083e-01 7.5409196e-02]\n",
      " [1.0000000e+00 3.5297774e-14]\n",
      " [1.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [3.2668115e-16 1.0000000e+00]\n",
      " [5.2217350e-27 1.0000000e+00]\n",
      " [1.2876041e-18 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# check the min/max probabilities of predicted kithara / no-kithara labels\n",
    "print(test_predictions.min(axis = 0))\n",
    "print(test_predictions.max(axis = 0))\n",
    "\n",
    "# print the names of the classes for clarity\n",
    "print(class_names)\n",
    "\n",
    "# return the array of predictions\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07576027",
   "metadata": {},
   "source": [
    "#### Convert the probabilities to class predictions\n",
    "*The cell below converts the array of probabilities into a class prediction for a binary yes/no response to 'is it a kithara?' The probability threshold for determining whether or not an image contains a kithara can be adjusted here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc96d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# convert the probabilities into a binary class prediction\n",
    "# adjust the threshold as needed to optimize for precision / recall\n",
    "# N.B. the threshold is set based on probability of a `no-kithara` label\n",
    "predicted_class = (test_predictions[:,1]>=0.95).astype(int)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896d1bf6",
   "metadata": {},
   "source": [
    "### Performance Analysis\n",
    "*Performance analysis for model 5.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e0a7da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.15755385160446167,\n",
       "  0.09793040156364441,\n",
       "  0.08449581265449524,\n",
       "  0.07499546557664871,\n",
       "  0.06762021034955978,\n",
       "  0.058213915675878525,\n",
       "  0.05850190296769142,\n",
       "  0.051442597061395645,\n",
       "  0.04441189393401146,\n",
       "  0.054929617792367935,\n",
       "  0.048340290784835815,\n",
       "  0.05687691643834114,\n",
       "  0.042964231222867966,\n",
       "  0.04608211666345596,\n",
       "  0.048458032310009,\n",
       "  0.04153943061828613,\n",
       "  0.031519822776317596,\n",
       "  0.032889027148485184,\n",
       "  0.03710458427667618,\n",
       "  0.0314088836312294],\n",
       " 'binary_accuracy': [0.9448552131652832,\n",
       "  0.9661121368408203,\n",
       "  0.9670363664627075,\n",
       "  0.9750462174415588,\n",
       "  0.975970447063446,\n",
       "  0.9784349799156189,\n",
       "  0.9827479720115662,\n",
       "  0.9827479720115662,\n",
       "  0.9855206608772278,\n",
       "  0.9827479720115662,\n",
       "  0.9836722016334534,\n",
       "  0.9824399352073669,\n",
       "  0.9879851937294006,\n",
       "  0.9830560684204102,\n",
       "  0.9839802980422974,\n",
       "  0.9882932901382446,\n",
       "  0.9870610237121582,\n",
       "  0.9901416897773743,\n",
       "  0.9889094233512878,\n",
       "  0.9904497861862183],\n",
       " 'false_negatives': [179.0,\n",
       "  110.0,\n",
       "  107.0,\n",
       "  81.0,\n",
       "  78.0,\n",
       "  70.0,\n",
       "  56.0,\n",
       "  56.0,\n",
       "  47.0,\n",
       "  56.0,\n",
       "  53.0,\n",
       "  57.0,\n",
       "  39.0,\n",
       "  55.0,\n",
       "  52.0,\n",
       "  38.0,\n",
       "  42.0,\n",
       "  32.0,\n",
       "  36.0,\n",
       "  31.0],\n",
       " 'false_positives': [179.0,\n",
       "  110.0,\n",
       "  107.0,\n",
       "  81.0,\n",
       "  78.0,\n",
       "  70.0,\n",
       "  56.0,\n",
       "  56.0,\n",
       "  47.0,\n",
       "  56.0,\n",
       "  53.0,\n",
       "  57.0,\n",
       "  39.0,\n",
       "  55.0,\n",
       "  52.0,\n",
       "  38.0,\n",
       "  42.0,\n",
       "  32.0,\n",
       "  36.0,\n",
       "  31.0],\n",
       " 'true_negatives': [3067.0,\n",
       "  3136.0,\n",
       "  3139.0,\n",
       "  3165.0,\n",
       "  3168.0,\n",
       "  3176.0,\n",
       "  3190.0,\n",
       "  3190.0,\n",
       "  3199.0,\n",
       "  3190.0,\n",
       "  3193.0,\n",
       "  3189.0,\n",
       "  3207.0,\n",
       "  3191.0,\n",
       "  3194.0,\n",
       "  3208.0,\n",
       "  3204.0,\n",
       "  3214.0,\n",
       "  3210.0,\n",
       "  3215.0],\n",
       " 'true_positives': [3067.0,\n",
       "  3136.0,\n",
       "  3139.0,\n",
       "  3165.0,\n",
       "  3168.0,\n",
       "  3176.0,\n",
       "  3190.0,\n",
       "  3190.0,\n",
       "  3199.0,\n",
       "  3190.0,\n",
       "  3193.0,\n",
       "  3189.0,\n",
       "  3207.0,\n",
       "  3191.0,\n",
       "  3194.0,\n",
       "  3208.0,\n",
       "  3204.0,\n",
       "  3214.0,\n",
       "  3210.0,\n",
       "  3215.0],\n",
       " 'auc': [0.9826660752296448,\n",
       "  0.9888109564781189,\n",
       "  0.9926541447639465,\n",
       "  0.9910086393356323,\n",
       "  0.9944192171096802,\n",
       "  0.9944241046905518,\n",
       "  0.992640495300293,\n",
       "  0.9948787689208984,\n",
       "  0.9951421022415161,\n",
       "  0.9953529834747314,\n",
       "  0.9949087500572205,\n",
       "  0.9940527081489563,\n",
       "  0.996221661567688,\n",
       "  0.9963183403015137,\n",
       "  0.9947395324707031,\n",
       "  0.9958722591400146,\n",
       "  0.9971969127655029,\n",
       "  0.9957325458526611,\n",
       "  0.9965351819992065,\n",
       "  0.9963492155075073],\n",
       " 'precision': [0.9448552131652832,\n",
       "  0.9661121368408203,\n",
       "  0.9670363664627075,\n",
       "  0.9750462174415588,\n",
       "  0.975970447063446,\n",
       "  0.9784349799156189,\n",
       "  0.9827479720115662,\n",
       "  0.9827479720115662,\n",
       "  0.9855206608772278,\n",
       "  0.9827479720115662,\n",
       "  0.9836722016334534,\n",
       "  0.9824399352073669,\n",
       "  0.9879851937294006,\n",
       "  0.9830560684204102,\n",
       "  0.9839802980422974,\n",
       "  0.9882932901382446,\n",
       "  0.9870610237121582,\n",
       "  0.9901416897773743,\n",
       "  0.9889094233512878,\n",
       "  0.9904497861862183],\n",
       " 'recall': [0.9448552131652832,\n",
       "  0.9661121368408203,\n",
       "  0.9670363664627075,\n",
       "  0.9750462174415588,\n",
       "  0.975970447063446,\n",
       "  0.9784349799156189,\n",
       "  0.9827479720115662,\n",
       "  0.9827479720115662,\n",
       "  0.9855206608772278,\n",
       "  0.9827479720115662,\n",
       "  0.9836722016334534,\n",
       "  0.9824399352073669,\n",
       "  0.9879851937294006,\n",
       "  0.9830560684204102,\n",
       "  0.9839802980422974,\n",
       "  0.9882932901382446,\n",
       "  0.9870610237121582,\n",
       "  0.9901416897773743,\n",
       "  0.9889094233512878,\n",
       "  0.9904497861862183],\n",
       " 'val_loss': [0.3429381549358368,\n",
       "  0.1536133885383606,\n",
       "  0.548528254032135,\n",
       "  0.07840857654809952,\n",
       "  0.06233867630362511,\n",
       "  0.15412333607673645,\n",
       "  0.06176862120628357,\n",
       "  0.0612415112555027,\n",
       "  0.06942250579595566,\n",
       "  0.0747588649392128,\n",
       "  0.06747665256261826,\n",
       "  0.07317719608545303,\n",
       "  0.06700640916824341,\n",
       "  0.051252298057079315,\n",
       "  0.09977289289236069,\n",
       "  0.05972808226943016,\n",
       "  0.08357271552085876,\n",
       "  0.041579365730285645,\n",
       "  0.06486029922962189,\n",
       "  0.06405598670244217],\n",
       " 'val_binary_accuracy': [0.9630314111709595,\n",
       "  0.9741219878196716,\n",
       "  0.9528650641441345,\n",
       "  0.9796673059463501,\n",
       "  0.9796673059463501,\n",
       "  0.9750462174415588,\n",
       "  0.9796673059463501,\n",
       "  0.9815157055854797,\n",
       "  0.9805914759635925,\n",
       "  0.9787430763244629,\n",
       "  0.9842883348464966,\n",
       "  0.9787430763244629,\n",
       "  0.9815157055854797,\n",
       "  0.9796673059463501,\n",
       "  0.9750462174415588,\n",
       "  0.9805914759635925,\n",
       "  0.9824399352073669,\n",
       "  0.986136794090271,\n",
       "  0.9833641648292542,\n",
       "  0.9815157055854797],\n",
       " 'val_false_negatives': [40.0,\n",
       "  28.0,\n",
       "  51.0,\n",
       "  22.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  22.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  23.0,\n",
       "  17.0,\n",
       "  23.0,\n",
       "  20.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  20.0],\n",
       " 'val_false_positives': [40.0,\n",
       "  28.0,\n",
       "  51.0,\n",
       "  22.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  22.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  23.0,\n",
       "  17.0,\n",
       "  23.0,\n",
       "  20.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  20.0],\n",
       " 'val_true_negatives': [1042.0,\n",
       "  1054.0,\n",
       "  1031.0,\n",
       "  1060.0,\n",
       "  1060.0,\n",
       "  1055.0,\n",
       "  1060.0,\n",
       "  1062.0,\n",
       "  1061.0,\n",
       "  1059.0,\n",
       "  1065.0,\n",
       "  1059.0,\n",
       "  1062.0,\n",
       "  1060.0,\n",
       "  1055.0,\n",
       "  1061.0,\n",
       "  1063.0,\n",
       "  1067.0,\n",
       "  1064.0,\n",
       "  1062.0],\n",
       " 'val_true_positives': [1042.0,\n",
       "  1054.0,\n",
       "  1031.0,\n",
       "  1060.0,\n",
       "  1060.0,\n",
       "  1055.0,\n",
       "  1060.0,\n",
       "  1062.0,\n",
       "  1061.0,\n",
       "  1059.0,\n",
       "  1065.0,\n",
       "  1059.0,\n",
       "  1062.0,\n",
       "  1060.0,\n",
       "  1055.0,\n",
       "  1061.0,\n",
       "  1063.0,\n",
       "  1067.0,\n",
       "  1064.0,\n",
       "  1062.0],\n",
       " 'val_auc': [0.9705832600593567,\n",
       "  0.9808698892593384,\n",
       "  0.9646987318992615,\n",
       "  0.9908322095870972,\n",
       "  0.9929309487342834,\n",
       "  0.9855824112892151,\n",
       "  0.9917683005332947,\n",
       "  0.992953896522522,\n",
       "  0.9920955896377563,\n",
       "  0.9882509112358093,\n",
       "  0.9922800064086914,\n",
       "  0.9900925159454346,\n",
       "  0.9902248978614807,\n",
       "  0.9947057962417603,\n",
       "  0.9862299561500549,\n",
       "  0.9920766949653625,\n",
       "  0.9867833852767944,\n",
       "  0.9950585961341858,\n",
       "  0.9905051589012146,\n",
       "  0.9912540316581726],\n",
       " 'val_precision': [0.9630314111709595,\n",
       "  0.9741219878196716,\n",
       "  0.9528650641441345,\n",
       "  0.9796673059463501,\n",
       "  0.9796673059463501,\n",
       "  0.9750462174415588,\n",
       "  0.9796673059463501,\n",
       "  0.9815157055854797,\n",
       "  0.9805914759635925,\n",
       "  0.9787430763244629,\n",
       "  0.9842883348464966,\n",
       "  0.9787430763244629,\n",
       "  0.9815157055854797,\n",
       "  0.9796673059463501,\n",
       "  0.9750462174415588,\n",
       "  0.9805914759635925,\n",
       "  0.9824399352073669,\n",
       "  0.986136794090271,\n",
       "  0.9833641648292542,\n",
       "  0.9815157055854797],\n",
       " 'val_recall': [0.9630314111709595,\n",
       "  0.9741219878196716,\n",
       "  0.9528650641441345,\n",
       "  0.9796673059463501,\n",
       "  0.9796673059463501,\n",
       "  0.9750462174415588,\n",
       "  0.9796673059463501,\n",
       "  0.9815157055854797,\n",
       "  0.9805914759635925,\n",
       "  0.9787430763244629,\n",
       "  0.9842883348464966,\n",
       "  0.9787430763244629,\n",
       "  0.9815157055854797,\n",
       "  0.9796673059463501,\n",
       "  0.9750462174415588,\n",
       "  0.9805914759635925,\n",
       "  0.9824399352073669,\n",
       "  0.986136794090271,\n",
       "  0.9833641648292542,\n",
       "  0.9815157055854797]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the metrics from each epoch\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50625768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the model's performance epoch-by-epoch\n",
    "\n",
    "# set accuracy variables\n",
    "acc = history.history['binary_accuracy']\n",
    "val_acc = history.history['val_binary_accuracy']\n",
    "\n",
    "# set loss variables\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# set epoch range\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "# plot accuracy for training vs. testing dataset\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Testing Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Testing Accuracy')\n",
    "\n",
    "# plot loss for training vs. testing dataset\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Testing Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Testing Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba9343b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9787430683918669\n",
      "0.9860487804878049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     kithara       0.80      0.96      0.87        82\n",
      "  no-kithara       1.00      0.98      0.99      1000\n",
      "\n",
      "    accuracy                           0.98      1082\n",
      "   macro avg       0.90      0.97      0.93      1082\n",
      "weighted avg       0.98      0.98      0.98      1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy of the kithara identification compared to the predicted class with the threshold set above\n",
    "print(accuracy_score(test_labels, predicted_class))\n",
    "\n",
    "# print the AUC for the model\n",
    "print(roc_auc_score(test_labels, test_predictions[:,1]))\n",
    "\n",
    "# print the overall classification report with precision, recall, accuracy, and f1-scores\n",
    "print(classification_report(test_labels, predicted_class, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e0895c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>actuals</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>kithara\\IMAG9871b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.067250e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kithara\\IMAG0366-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>5.179865e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>kithara\\IMAG9869b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>8.062929e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kithara\\IMAG1845-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>4.382669e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>kithara\\IMAG2027-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>8.808910e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>kithara\\IMAG2467-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.131403e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kithara\\IMAG0009-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.245908e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kithara\\IMAG0106b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.908850e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kithara\\IMAG1400b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.925928e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kithara\\IMAG9870a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.988320e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kithara\\IMAG1846a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.990668e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kithara\\IMAG0077-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.996033e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kithara\\IMAG0310-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999887e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>kithara\\IMAG2554-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999976e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kithara\\IMAG8888-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999983e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>kithara\\IMAG2764-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>kithara\\IMAG7032-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kithara\\IMAG0354-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>kithara\\IMAG8179-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kithara\\IMAG8223-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kithara\\IMAG8225b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kithara\\IMAG8243-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>kithara\\IMAG8605-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>kithara\\IMAG8941-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>kithara\\IMAG8958-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>kithara\\IMAG8969-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>kithara\\IMAG9080-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>kithara\\IMAG9100b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>kithara\\IMAG9131-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>kithara\\IMAG9197-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kithara\\IMAG9219-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>kithara\\IMAG9220-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>kithara\\IMAG9941-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>kithara\\IMAG9936-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kithara\\IMAG0062-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kithara\\IMAG0066-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kithara\\IMAG0080-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>kithara\\IMAG9869a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>kithara\\IMAG7027-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>kithara\\IMAG9854-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kithara\\IMAG9829-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kithara\\IMAG9824-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kithara\\IMAG9758-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kithara\\IMAG9424-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kithara\\IMAG9282-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>kithara\\IMAG9228-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>kithara\\IMAG9830-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>kithara\\IMAG6607-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>kithara\\IMAG6151a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>kithara\\IMAG5980-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kithara\\IMAG0455-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kithara\\IMAG0742b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kithara\\IMAG0745-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kithara\\IMAG0916-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kithara\\IMAG10036-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kithara\\IMAG10045-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kithara\\IMAG10097a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kithara\\IMAG1399-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kithara\\IMAG0304-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kithara\\IMAG1463-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kithara\\IMAG1544-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kithara\\IMAG1551-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kithara\\IMAG1554-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kithara\\IMAG1837-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kithara\\IMAG0356-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kithara\\IMAG0266-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kithara\\IMAG1892-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kithara\\IMAG1979-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>kithara\\IMAG2026-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kithara\\IMAG0163-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>kithara\\IMAG2104a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>kithara\\IMAG2172-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>kithara\\IMAG2306-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kithara\\IMAG2465b-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kithara\\IMAG0130-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>kithara\\IMAG9949-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>kithara\\IMAG2556-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>kithara\\IMAG2568-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>kithara\\IMAG2609-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>kithara\\IMAG2635a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kithara\\IMAG0166-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>kithara\\IMAG9950a-kithara-full.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filepath  actuals   predictions\n",
       "77   kithara\\IMAG9871b-kithara-full.jpg        0  1.067250e-09\n",
       "14    kithara\\IMAG0366-kithara-full.jpg        0  5.179865e-08\n",
       "75   kithara\\IMAG9869b-kithara-full.jpg        0  8.062929e-03\n",
       "29    kithara\\IMAG1845-kithara-full.jpg        0  4.382669e-01\n",
       "34    kithara\\IMAG2027-kithara-full.jpg        0  8.808910e-01\n",
       "39    kithara\\IMAG2467-kithara-full.jpg        0  9.131403e-01\n",
       "0     kithara\\IMAG0009-kithara-full.jpg        0  9.245908e-01\n",
       "5    kithara\\IMAG0106b-kithara-full.jpg        0  9.908850e-01\n",
       "23   kithara\\IMAG1400b-kithara-full.jpg        0  9.925928e-01\n",
       "76   kithara\\IMAG9870a-kithara-full.jpg        0  9.988320e-01\n",
       "30   kithara\\IMAG1846a-kithara-full.jpg        0  9.990668e-01\n",
       "3     kithara\\IMAG0077-kithara-full.jpg        0  9.996033e-01\n",
       "11    kithara\\IMAG0310-kithara-full.jpg        0  9.999887e-01\n",
       "40    kithara\\IMAG2554-kithara-full.jpg        0  9.999976e-01\n",
       "56    kithara\\IMAG8888-kithara-full.jpg        0  9.999983e-01\n",
       "45    kithara\\IMAG2764-kithara-full.jpg        0  9.999999e-01\n",
       "50    kithara\\IMAG7032-kithara-full.jpg        0  9.999999e-01\n",
       "12    kithara\\IMAG0354-kithara-full.jpg        0  1.000000e+00\n",
       "51    kithara\\IMAG8179-kithara-full.jpg        0  1.000000e+00\n",
       "52    kithara\\IMAG8223-kithara-full.jpg        0  1.000000e+00\n",
       "53   kithara\\IMAG8225b-kithara-full.jpg        0  1.000000e+00\n",
       "54    kithara\\IMAG8243-kithara-full.jpg        0  1.000000e+00\n",
       "55    kithara\\IMAG8605-kithara-full.jpg        0  1.000000e+00\n",
       "57    kithara\\IMAG8941-kithara-full.jpg        0  1.000000e+00\n",
       "58    kithara\\IMAG8958-kithara-full.jpg        0  1.000000e+00\n",
       "59    kithara\\IMAG8969-kithara-full.jpg        0  1.000000e+00\n",
       "60    kithara\\IMAG9080-kithara-full.jpg        0  1.000000e+00\n",
       "61   kithara\\IMAG9100b-kithara-full.jpg        0  1.000000e+00\n",
       "62    kithara\\IMAG9131-kithara-full.jpg        0  1.000000e+00\n",
       "63    kithara\\IMAG9197-kithara-full.jpg        0  1.000000e+00\n",
       "64    kithara\\IMAG9219-kithara-full.jpg        0  1.000000e+00\n",
       "65    kithara\\IMAG9220-kithara-full.jpg        0  1.000000e+00\n",
       "79    kithara\\IMAG9941-kithara-full.jpg        0  1.000000e+00\n",
       "78    kithara\\IMAG9936-kithara-full.jpg        0  1.000000e+00\n",
       "1     kithara\\IMAG0062-kithara-full.jpg        0  1.000000e+00\n",
       "2     kithara\\IMAG0066-kithara-full.jpg        0  1.000000e+00\n",
       "4     kithara\\IMAG0080-kithara-full.jpg        0  1.000000e+00\n",
       "74   kithara\\IMAG9869a-kithara-full.jpg        0  1.000000e+00\n",
       "49    kithara\\IMAG7027-kithara-full.jpg        0  1.000000e+00\n",
       "73    kithara\\IMAG9854-kithara-full.jpg        0  1.000000e+00\n",
       "71    kithara\\IMAG9829-kithara-full.jpg        0  1.000000e+00\n",
       "70    kithara\\IMAG9824-kithara-full.jpg        0  1.000000e+00\n",
       "69    kithara\\IMAG9758-kithara-full.jpg        0  1.000000e+00\n",
       "68    kithara\\IMAG9424-kithara-full.jpg        0  1.000000e+00\n",
       "67    kithara\\IMAG9282-kithara-full.jpg        0  1.000000e+00\n",
       "66    kithara\\IMAG9228-kithara-full.jpg        0  1.000000e+00\n",
       "72    kithara\\IMAG9830-kithara-full.jpg        0  1.000000e+00\n",
       "48    kithara\\IMAG6607-kithara-full.jpg        0  1.000000e+00\n",
       "47   kithara\\IMAG6151a-kithara-full.jpg        0  1.000000e+00\n",
       "46    kithara\\IMAG5980-kithara-full.jpg        0  1.000000e+00\n",
       "15    kithara\\IMAG0455-kithara-full.jpg        0  1.000000e+00\n",
       "16   kithara\\IMAG0742b-kithara-full.jpg        0  1.000000e+00\n",
       "17    kithara\\IMAG0745-kithara-full.jpg        0  1.000000e+00\n",
       "18    kithara\\IMAG0916-kithara-full.jpg        0  1.000000e+00\n",
       "19   kithara\\IMAG10036-kithara-full.jpg        0  1.000000e+00\n",
       "20   kithara\\IMAG10045-kithara-full.jpg        0  1.000000e+00\n",
       "21  kithara\\IMAG10097a-kithara-full.jpg        0  1.000000e+00\n",
       "22    kithara\\IMAG1399-kithara-full.jpg        0  1.000000e+00\n",
       "10    kithara\\IMAG0304-kithara-full.jpg        0  1.000000e+00\n",
       "24    kithara\\IMAG1463-kithara-full.jpg        0  1.000000e+00\n",
       "25    kithara\\IMAG1544-kithara-full.jpg        0  1.000000e+00\n",
       "26    kithara\\IMAG1551-kithara-full.jpg        0  1.000000e+00\n",
       "27    kithara\\IMAG1554-kithara-full.jpg        0  1.000000e+00\n",
       "28    kithara\\IMAG1837-kithara-full.jpg        0  1.000000e+00\n",
       "13    kithara\\IMAG0356-kithara-full.jpg        0  1.000000e+00\n",
       "9     kithara\\IMAG0266-kithara-full.jpg        0  1.000000e+00\n",
       "31    kithara\\IMAG1892-kithara-full.jpg        0  1.000000e+00\n",
       "32    kithara\\IMAG1979-kithara-full.jpg        0  1.000000e+00\n",
       "33    kithara\\IMAG2026-kithara-full.jpg        0  1.000000e+00\n",
       "7     kithara\\IMAG0163-kithara-full.jpg        0  1.000000e+00\n",
       "35   kithara\\IMAG2104a-kithara-full.jpg        0  1.000000e+00\n",
       "36    kithara\\IMAG2172-kithara-full.jpg        0  1.000000e+00\n",
       "37    kithara\\IMAG2306-kithara-full.jpg        0  1.000000e+00\n",
       "38   kithara\\IMAG2465b-kithara-full.jpg        0  1.000000e+00\n",
       "6     kithara\\IMAG0130-kithara-full.jpg        0  1.000000e+00\n",
       "80    kithara\\IMAG9949-kithara-full.jpg        0  1.000000e+00\n",
       "41    kithara\\IMAG2556-kithara-full.jpg        0  1.000000e+00\n",
       "42    kithara\\IMAG2568-kithara-full.jpg        0  1.000000e+00\n",
       "43    kithara\\IMAG2609-kithara-full.jpg        0  1.000000e+00\n",
       "44   kithara\\IMAG2635a-kithara-full.jpg        0  1.000000e+00\n",
       "8     kithara\\IMAG0166-kithara-full.jpg        0  1.000000e+00\n",
       "81   kithara\\IMAG9950a-kithara-full.jpg        0  1.000000e+00"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe to hold the filenames, actual values, and predicted no-kithara probability\n",
    "pred_df = pd.DataFrame({'filepath': filepaths, 'actuals': test_labels, 'predictions': test_predictions[:,0]})\n",
    "\n",
    "# take a look at the dataframe where the known value was a kithara\n",
    "pred_df[pred_df['actuals'] == 0].sort_values('predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0ea7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check to see if specific images are included in the training dataset\n",
    "# pred_df01[pred_df01['filepath'].str.contains('IMAG9081')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
